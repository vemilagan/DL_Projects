{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyMsK5DFlisR"
      },
      "source": [
        "# Project 1: Training a Simple Neural Network with GPU\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this project, you will create, train, and evaluate a simple neural network using both TensorFlow and PyTorch. The objective is to ensure you are comfortable with setting up a neural network and utilizing GPU acceleration for training. You will use the MNIST dataset for this project.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "1. Set up TensorFlow and PyTorch environments.\n",
        "2. Verify GPU availability.\n",
        "3. Implement a simple neural network in TensorFlow and PyTorch.\n",
        "4. Train and evaluate the models.\n",
        "5. Answer assessment questions.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Follow the steps below to complete the project. Ensure that you use a GPU to train your models.\n",
        "\n",
        "---\n",
        "\n",
        "### Step 1: Set Up Your Environment\n",
        "\n",
        "First, install the necessary libraries. Run the following cell to install TensorFlow and PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgL3rSPFlisU"
      },
      "source": [
        "Provide snapshots from your environment showing:\n",
        "1) You are using a virtual environment\n",
        "2) You have installed `TensorFlow` and `PyTorch`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XppbgvfXlisV"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 2: Verify GPU Availability\n",
        "Check if TensorFlow and PyTorch can detect the GPU.\n",
        "\n",
        "Run the following two code blocks and show the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi3QBcIklisV"
      },
      "source": [
        "#### TensorFlow GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvXNxc89lisW",
        "outputId": "164d9f73-fc14-4e50-d67f-84b3c2a9a899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "GPU is available for TensorFlow!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print(\"GPU is available for TensorFlow!\")\n",
        "else:\n",
        "    print(\"No GPU found for TensorFlow.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOjDMgkulisX"
      },
      "source": [
        "#### PyTorch GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DTUI9WulisY",
        "outputId": "695dab39-e731-49c4-8cab-3cc97116c764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.0+cu121\n",
            "GPU is available for PyTorch!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available for PyTorch!\")\n",
        "else:\n",
        "    print(\"No GPU found for PyTorch.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFKK4Bh_lisY"
      },
      "source": [
        "---\n",
        "\n",
        "### Step 3: Implement and Train a Simple Neural Network\n",
        "#### TensorFlow Implementation\n",
        "1. Load and preprocess the MNIST dataset.\n",
        "2. Define the neural network model.\n",
        "3. Compile the model.\n",
        "4. Train the model using the GPU.\n",
        "5. Evaluate the model.\n",
        "\n",
        "You need to complete and run the code. Show the complete output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyoYuRGVlisY",
        "outputId": "752ec289-7555-4193-9679-604fe94437e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/5\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.2704 - accuracy: 0.9240 - val_loss: 0.1227 - val_accuracy: 0.9693\n",
            "Epoch 2/5\n",
            "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1161 - accuracy: 0.9657 - val_loss: 0.0921 - val_accuracy: 0.9747\n",
            "Epoch 3/5\n",
            "1688/1688 [==============================] - 6s 3ms/step - loss: 0.0797 - accuracy: 0.9752 - val_loss: 0.0842 - val_accuracy: 0.9753\n",
            "Epoch 4/5\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 0.0772 - val_accuracy: 0.9782\n",
            "Epoch 5/5\n",
            "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9858 - val_loss: 0.0689 - val_accuracy: 0.9807\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0740 - accuracy: 0.9779\n",
            "Test accuracy: 0.9779\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test)= mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "with tf.device('/GPU:0'):\n",
        "    model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99kW0YiQlisY"
      },
      "source": [
        "#### PyTorch Implementation\n",
        "1. Load and preprocess the MNIST dataset.\n",
        "2. Define the neural network model.\n",
        "3. Define loss function and optimizer.\n",
        "4. Train the model using the GPU.\n",
        "5. Evaluate the model.\n",
        "\n",
        "You need to complete and run the code. Show the complete output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRGkccONlisZ",
        "outputId": "d59a3009-89b2-4688-ea65-7dadc1a729e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:02<00:00, 4169647.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 133358.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:06<00:00, 240373.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8612354.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/5], Loss: 0.2222\n",
            "Epoch [2/5], Loss: 0.2132\n",
            "Epoch [3/5], Loss: 0.1062\n",
            "Epoch [4/5], Loss: 0.1892\n",
            "Epoch [5/5], Loss: 0.0273\n",
            "Test Accuracy: 96.11%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "covA4Q07lisZ"
      },
      "source": [
        "---\n",
        "### Questions\n",
        "Answer the following questions in detail.\n",
        "\n",
        "1. What is the purpose of normalizing the input data in both TensorFlow and PyTorch implementations?\n",
        "\n",
        "* **Answer:** Normalization ensures that the input data is scaled to a standard range, typically between 0 and 1. This helps accelerate the convergence of the training process. Normalized data provides stable gradients during backpropagation and prevents issues like vanishing or exploding gradients. It ensures that all input features contribute equally to the learning process.\n",
        "\n",
        "\n",
        "2. Explain the role of the activation function relu in the neural network.\n",
        "* **Answer:** The ReLU (Rectified Linear Unit) activation function introduces non-linearity into the neural network, allowing it to learn complex patterns. It outputs the input directly if it is positive, otherwise, it outputs zero, which helps in mitigating the vanishing gradient problem. ReLU also activates only a subset of neurons at a time, making the network more efficient. Additionally, it is computationally efficient due to its simple mathematical operation.\n",
        "\n",
        "\n",
        "3. Why is it important to use GPU for training neural networks?\n",
        "* **Answer:** Using a GPU for training neural networks is important because it allows for parallel processing, significantly speeding up the computation of matrix and vector operations. GPUs handle the high computational demands of training deep networks more efficiently than CPUs. They reduce the training time considerably, making it feasible to work with large datasets and complex models. Additionally, GPUs provide scalability, essential for handling extensive training processes in deep learning.\n",
        "\n",
        "4. Compare the training time and accuracy of the TensorFlow and PyTorch models. Which one performed better and why?\n",
        "* **Answer:**\n",
        "\n",
        "* **Comparison of Training Time and Accuracy**\n",
        "\n",
        "The TensorFlow model trained for approximately 8 seconds in the first epoch and 5-7 seconds for each of the subsequent epochs. It achieved a validation accuracy of 98.07% at the end of 5 epochs and a test accuracy of 97.79%. Although the exact training times for the PyTorch model were not provided, they are typically comparable to TensorFlow when using the same hardware and batch sizes due to GPU acceleration. The PyTorch model achieved a test accuracy of 96.11%.\n",
        "\n",
        "\n",
        "* **Which One Performed Better and Why?**\n",
        "\n",
        "In terms of accuracy, the TensorFlow model performed better, achieving a higher test accuracy of 97.79% compared to PyTorch's 96.11%. This indicates that the TensorFlow model generalized slightly better on the MNIST dataset for this specific implementation.\n",
        "\n",
        "Both TensorFlow and PyTorch leverage GPU acceleration, resulting in fast training times. Although the exact training times for PyTorch were not provided, they are typically similar to TensorFlow's when using the same hardware and batch sizes.\n",
        "\n",
        "The minor difference in accuracy could be due to implementation specifics, such as initial weights, slight variations in training processes, or optimization settings. TensorFlow might have better initial default settings or slight differences in the way it handles certain operations that contributed to the marginally higher accuracy. Additionally, TensorFlow and PyTorch have different internal optimizations, which can affect performance and accuracy slightly.\n",
        "\n",
        "In conclusion, the TensorFlow model performed better in terms of accuracy, achieving 97.79% compared to PyTorch's 96.11%. Both frameworks are efficient with GPU, and the training times are likely comparable. The specific implementation and possible optimizations within TensorFlow might have contributed to slightly better performance in this instance. It is also possible that the TensorFlow model's training process better handled the dataset characteristics, leading to improved generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlCoV1xblisZ"
      },
      "source": [
        "---\n",
        "### Submission\n",
        "Submit a link to your completed Jupyter Notebook (e.g., on GitHub (private) or Google Colab) with all the cells executed, and answers to the assessment questions included at the end of the notebook."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}